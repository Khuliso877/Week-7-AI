Project Overview
â€¢ 	Brief description of the COMPAS dataset and its significance in criminal justice.
â€¢ 	Your goal: auditing racial bias in risk scores using AI Fairness 360.
â€¢ 	Why this matters: ethical AI, transparency, and fairness in high-stakes decision-making.
2. ğŸ” Dataset Details
â€¢ 	Source: ProPublicaâ€™s COMPAS dataset.
â€¢ 	Key features: race, age, priors count, charge degree, two-year recidivism.
â€¢ 	Protected attribute: race (African-American vs Caucasian).
3. ğŸ› ï¸ Tools & Libraries
â€¢ 	Python
â€¢ 	AI Fairness 360 (IBM)
â€¢ 	scikit-learn
â€¢ 	matplotlib / seaborn
4. ğŸ“Š Methodology
â€¢ 	Load and preprocess dataset.
â€¢ 	Compute fairness metrics: disparate impact, statistical parity, false positive rate difference.
â€¢ 	Train baseline classifier (e.g., logistic regression).
â€¢ 	Apply bias mitigation (e.g., reweighing).
â€¢ 	Visualize disparities before and after mitigation.
